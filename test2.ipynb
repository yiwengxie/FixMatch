{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import argparse\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "\n",
    "cifar10_mean = (0.4914, 0.4822, 0.4465)\n",
    "cifar10_std = (0.2471, 0.2435, 0.2616)\n",
    "cifar100_mean = (0.5071, 0.4867, 0.4408)\n",
    "cifar100_std = (0.2675, 0.2565, 0.2761)\n",
    "normal_mean = (0.5, 0.5, 0.5)\n",
    "normal_std = (0.5, 0.5, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_config():\n",
    "    parser = argparse.ArgumentParser(description='PyTorch FixMatch Training')\n",
    "    parser.add_argument('--gpu-id', default='0', type=int, help='id(s) for CUDA_VISIBLE_DEVICES')\n",
    "    parser.add_argument('--num-workers', type=int, default=4, help='number of workers')\n",
    "    parser.add_argument('--dataset', default='cifar10', type=str, choices=['cifar10', 'cifar100'], help='dataset name')\n",
    "    parser.add_argument('--num-labeled', type=int, default=4000, help='number of labeled data')\n",
    "    parser.add_argument(\"--expand-labels\", action=\"store_true\", help=\"expand labels to fit eval steps\")\n",
    "    parser.add_argument('--arch', default='wideresnet', type=str, choices=['wideresnet', 'resnext'], help='dataset name')\n",
    "    parser.add_argument('--total-steps', default=1000, type=int, help='number of total steps to run')\n",
    "    parser.add_argument('--eval-step', default=1024, type=int, help='number of eval steps to run')\n",
    "    parser.add_argument('--start-epoch', default=0, type=int, help='manual epoch number (useful on restarts)')\n",
    "    parser.add_argument('--batch-size', default=64, type=int, help='train batchsize')\n",
    "    parser.add_argument('--lr', '--learning-rate', default=0.03, type=float, help='initial learning rate')\n",
    "    parser.add_argument('--warmup', default=0, type=float, help='warmup epochs (unlabeled data based)')\n",
    "    parser.add_argument('--wdecay', default=5e-4, type=float, help='weight decay')\n",
    "    parser.add_argument('--nesterov', action='store_true', default=True, help='use nesterov momentum')\n",
    "    parser.add_argument('--use-ema', action='store_true', default=True, help='use EMA model')\n",
    "    parser.add_argument('--ema-decay', default=0.999, type=float, help='EMA decay rate')\n",
    "    parser.add_argument('--mu', default=7, type=int, help='coefficient of unlabeled batch size')\n",
    "    parser.add_argument('--lambda-u', default=1, type=float, help='coefficient of unlabeled loss')\n",
    "    parser.add_argument('--T', default=1, type=float, help='pseudo label temperature')\n",
    "    parser.add_argument('--threshold', default=0.95, type=float, help='pseudo label threshold')\n",
    "    parser.add_argument('--out', default='results', help='directory to output the result')\n",
    "    parser.add_argument('--resume', default='', type=str, help='path to latest checkpoint (default: none)')\n",
    "    parser.add_argument('--seed', default=None, type=int, help=\"random seed\")\n",
    "    parser.add_argument(\"--amp\", action=\"store_true\", help=\"use 16-bit (mixed) precision through NVIDIA apex AMP\")\n",
    "    parser.add_argument(\"--opt_level\", type=str, default=\"O1\", help=\"apex AMP optimization level selected in ['O0', 'O1', 'O2', and 'O3'].\" \"See details at https://nvidia.github.io/apex/amp.html\")\n",
    "    parser.add_argument(\"--local_rank\", type=int, default=-1, help=\"For distributed training: local_rank\")\n",
    "    parser.add_argument('--no-progress', action='store_true', help=\"don't use progress bar\")\n",
    "    args = parser.parse_args()\n",
    "    return  args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def x_u_split(args, labels):\n",
    "    label_per_class = args[\"num_labeled\"] // args[\"num_classes\"]\n",
    "    labels = np.array(labels)\n",
    "    labeled_idx = []\n",
    "    # unlabeled data: all data (https://github.com/kekmodel/FixMatch-pytorch/issues/10)\n",
    "    unlabeled_idx = np.array(range(len(labels)))\n",
    "    for i in range(args[\"num_classes\"]):\n",
    "        idx = np.where(labels == i)[0]\n",
    "        idx = np.random.choice(idx, label_per_class, False)\n",
    "        labeled_idx.extend(idx)\n",
    "    labeled_idx = np.array(labeled_idx)\n",
    "    assert len(labeled_idx) == args[\"num_labeled\"] \n",
    "\n",
    "    if args[\"num_labeled\"]  < args[\"batch_size\"]:\n",
    "        num_expand_x = math.ceil(\n",
    "            args[\"batch_size\"] * args[\"eval_step\"] / args[\"num_labeled\"] )\n",
    "        labeled_idx = np.hstack([labeled_idx for _ in range(num_expand_x)])\n",
    "    np.random.shuffle(labeled_idx)\n",
    "    return labeled_idx, unlabeled_idx\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "root = './data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {'num_labeled': 4000, 'num_classes': 10, 'batch_size': 64, 'eval_step': 1024, 'local_rank': -1, 'num_workers': 4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAR10SSL(datasets.CIFAR10):\n",
    "    def __init__(self, root, indexs, train=True,\n",
    "                 transform=None, target_transform=None,\n",
    "                 download=False):\n",
    "        super().__init__(root, train=train,\n",
    "                         transform=transform,\n",
    "                         target_transform=target_transform,\n",
    "                         download=download)\n",
    "        if indexs is not None:\n",
    "            self.data = self.data[indexs]\n",
    "            self.targets = np.array(self.targets)[indexs]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img, target = self.data[index], self.targets[index]\n",
    "        img = Image.fromarray(img)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "\n",
    "        return img, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset.randaugment import RandAugmentMC\n",
    "\n",
    "class TransformFixMatch(object):\n",
    "    def __init__(self, mean, std):\n",
    "        self.weak = transforms.Compose([\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomCrop(size=32,\n",
    "                                  padding=int(32*0.125),\n",
    "                                  padding_mode='reflect')])\n",
    "        self.strong = transforms.Compose([\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomCrop(size=32,\n",
    "                                  padding=int(32*0.125),\n",
    "                                  padding_mode='reflect'),\n",
    "            RandAugmentMC(n=2, m=10)])\n",
    "        self.normalize = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=mean, std=std)])\n",
    "\n",
    "    def __call__(self, x):\n",
    "        weak = self.weak(x)\n",
    "        strong = self.strong(x)\n",
    "        return self.normalize(weak), self.normalize(strong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cifar10(args, root):\n",
    "    transform_labeled = transforms.Compose([\n",
    "        # transforms.RandomHorizontalFlip(),\n",
    "        # transforms.RandomCrop(size=32,\n",
    "        #                       padding=int(32*0.125),\n",
    "        #                       padding_mode='reflect'),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=cifar10_mean, std=cifar10_std)\n",
    "    ])\n",
    "    transform_val = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=cifar10_mean, std=cifar10_std)\n",
    "    ])\n",
    "    base_dataset = datasets.CIFAR10(root, train=True, download=True)\n",
    "\n",
    "    train_labeled_idxs, train_unlabeled_idxs = x_u_split(\n",
    "        args, base_dataset.targets)\n",
    "\n",
    "    train_labeled_dataset = CIFAR10SSL(\n",
    "        root, train_labeled_idxs, train=True,\n",
    "        transform=transform_labeled)\n",
    "\n",
    "    train_unlabeled_dataset = CIFAR10SSL(\n",
    "        root, train_unlabeled_idxs, train=True,\n",
    "        transform=TransformFixMatch(mean=cifar10_mean, std=cifar10_std))\n",
    "\n",
    "    test_dataset = datasets.CIFAR10(\n",
    "        root, train=False, transform=transform_val, download=False)\n",
    "\n",
    "    return train_labeled_dataset, train_unlabeled_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.5189,  0.5347,  0.6299,  ...,  0.1856,  0.0110, -0.1477],\n",
       "          [ 0.4236,  0.4078,  0.5347,  ...,  0.1697, -0.0049, -0.1001],\n",
       "          [ 0.4078,  0.4078,  0.5189,  ...,  0.2173,  0.0745, -0.0842],\n",
       "          ...,\n",
       "          [-0.9095, -1.3221, -1.4967,  ..., -1.3856, -1.7824, -1.3539],\n",
       "          [-1.0206, -1.2110, -1.4332,  ..., -1.5760, -1.5284, -1.6713],\n",
       "          [-1.1317, -1.0999, -1.2745,  ..., -1.6078, -1.4491, -1.6554]],\n",
       " \n",
       "         [[-0.1765, -0.1926, -0.1121,  ..., -0.4503, -0.5147, -0.6114],\n",
       "          [-0.1765, -0.2087, -0.1443,  ..., -0.4503, -0.5147, -0.5630],\n",
       "          [-0.2087, -0.2248, -0.1926,  ..., -0.4020, -0.4503, -0.5469],\n",
       "          ...,\n",
       "          [ 0.0167, -0.3698, -0.5630,  ..., -0.4181, -0.9496, -0.6114],\n",
       "          [-0.1121, -0.3376, -0.6114,  ..., -0.6597, -0.6597, -0.9496],\n",
       "          [-0.2571, -0.2893, -0.5469,  ..., -0.7402, -0.6275, -0.9013]],\n",
       " \n",
       "         [[-0.9723, -1.0022, -0.9423,  ..., -1.1671, -1.1671, -1.2121],\n",
       "          [-0.9423, -1.1072, -1.0322,  ..., -1.2421, -1.2271, -1.1971],\n",
       "          [-1.0022, -1.2121, -1.1671,  ..., -1.1971, -1.1971, -1.2121],\n",
       "          ...,\n",
       "          [ 0.9466,  0.5118,  0.3469,  ...,  0.4818, -0.0878,  0.1970],\n",
       "          [ 0.8116,  0.5118,  0.2720,  ...,  0.2420,  0.1820, -0.1028],\n",
       "          [ 0.6917,  0.5268,  0.2720,  ...,  0.1520,  0.2270, -0.0578]]]),\n",
       " 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labeled_dataset, train_unlabeled_dataset, test_dataset = get_cifar10(args, root)\n",
    "test_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "# 给定的张量和标签\n",
    "tensor_data, label = test_dataset[2]\n",
    "\n",
    "# 将张量数据从[-1, 1]范围转换到[0, 1]范围\n",
    "tensor_data = (tensor_data + 1) / 2\n",
    "\n",
    "\n",
    "# 将tensor转换为numpy数组，并交换通道以适应matplotlib的格式\n",
    "image_data = tensor_data.permute(1, 2, 0).numpy()\n",
    "\n",
    "# 显示图像\n",
    "plt.imshow(image_data)\n",
    "plt.title(f\"Label: {label}\")\n",
    "plt.axis('off')  # 关闭坐标轴\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "def create_data_loaders(args, labeled_dataset, unlabeled_dataset, test_dataset):\n",
    "    train_sampler = RandomSampler if args[\"local_rank\"] == -1 else DistributedSampler\n",
    "\n",
    "    labeled_trainloader = DataLoader(\n",
    "        labeled_dataset,\n",
    "        sampler=train_sampler(labeled_dataset),\n",
    "        batch_size=args['batch_size'],\n",
    "        num_workers=args['num_workers'],\n",
    "        drop_last=True)\n",
    "\n",
    "    unlabeled_trainloader = DataLoader(\n",
    "        unlabeled_dataset,\n",
    "        sampler=train_sampler(unlabeled_dataset),\n",
    "        batch_size=args['batch_size']*7,\n",
    "        num_workers=args['num_workers'],\n",
    "        drop_last=True)\n",
    "\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        sampler=SequentialSampler(test_dataset),\n",
    "        batch_size=args['batch_size'],\n",
    "        num_workers=args['num_workers'])\n",
    "\n",
    "    return labeled_trainloader, unlabeled_trainloader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_trainloader, unlabeled_trainloader, test_loader = create_data_loaders(args, train_labeled_dataset, train_unlabeled_dataset, test_dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
